{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1213c-0803-4be8-a11e-16a918a03b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched historical data:\n",
      "          Date          Open          High           Low         Close\n",
      "0  23-Jul-2024  24568.900391  24582.550781  24074.199219  24479.050781\n",
      "1  24-Jul-2024  24444.949219  24504.250000  24307.250000  24413.500000\n",
      "2  25-Jul-2024  24230.949219  24426.150391  24210.800781  24406.099609\n",
      "3  26-Jul-2024  24423.349609  24861.150391  24410.900391  24834.849609\n",
      "4  29-Jul-2024  24943.300781  24999.750000  24774.599609  24836.099609\n",
      "Data appended to C:\\Users\\rusha\\OneDrive\\Desktop\\STOCK_MARKET\\merged1.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\AppData\\Local\\Temp\\ipykernel_16160\\1792334546.py:72: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_df = pd.concat([existing_df, data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No internet connection. Will retry in 10 minutes.\n",
      "Fetched historical data:\n",
      "          Date          Open          High           Low         Close\n",
      "0  23-Jul-2024  24568.900391  24582.550781  24074.199219  24479.050781\n",
      "1  24-Jul-2024  24444.949219  24504.250000  24307.250000  24413.500000\n",
      "2  25-Jul-2024  24230.949219  24426.150391  24210.800781  24406.099609\n",
      "3  26-Jul-2024  24423.349609  24861.150391  24410.900391  24834.849609\n",
      "4  29-Jul-2024  24943.300781  24999.750000  24774.599609  24836.099609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\AppData\\Local\\Temp\\ipykernel_16160\\1792334546.py:72: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_df = pd.concat([existing_df, data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to C:\\Users\\rusha\\OneDrive\\Desktop\\STOCK_MARKET\\merged1.csv.\n",
      "Fetched historical data:\n",
      "          Date          Open          High           Low         Close\n",
      "0  23-Jul-2024  24568.900391  24582.550781  24074.199219  24479.050781\n",
      "1  24-Jul-2024  24444.949219  24504.250000  24307.250000  24413.500000\n",
      "2  25-Jul-2024  24230.949219  24426.150391  24210.800781  24406.099609\n",
      "3  26-Jul-2024  24423.349609  24861.150391  24410.900391  24834.849609\n",
      "4  29-Jul-2024  24943.300781  24999.750000  24774.599609  24836.099609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\AppData\\Local\\Temp\\ipykernel_16160\\1792334546.py:72: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_df = pd.concat([existing_df, data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to C:\\Users\\rusha\\OneDrive\\Desktop\\STOCK_MARKET\\merged1.csv.\n",
      "Fetched historical data:\n",
      "          Date          Open          High           Low         Close\n",
      "0  23-Jul-2024  24568.900391  24582.550781  24074.199219  24479.050781\n",
      "1  24-Jul-2024  24444.949219  24504.250000  24307.250000  24413.500000\n",
      "2  25-Jul-2024  24230.949219  24426.150391  24210.800781  24406.099609\n",
      "3  26-Jul-2024  24423.349609  24861.150391  24410.900391  24834.849609\n",
      "4  29-Jul-2024  24943.300781  24999.750000  24774.599609  24836.099609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rusha\\AppData\\Local\\Temp\\ipykernel_16160\\1792334546.py:72: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_df = pd.concat([existing_df, data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data appended to C:\\Users\\rusha\\OneDrive\\Desktop\\STOCK_MARKET\\merged1.csv.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Define the NIFTY 50 index ticker\n",
    "nifty50_ticker = '^NSEI'\n",
    "csv_file = 'C:\\\\Users\\\\rusha\\\\OneDrive\\\\Desktop\\\\STOCK_MARKET\\\\merged1.csv'\n",
    "required_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Shares Traded', 'Turnover (₹ Cr)']\n",
    "\n",
    "# Function to check internet connectivity\n",
    "def check_internet_connection(url='http://www.google.com/', timeout=5):\n",
    "    try:\n",
    "        _ = requests.get(url, timeout=timeout)\n",
    "        return True\n",
    "    except requests.ConnectionError:\n",
    "        return False\n",
    "\n",
    "# Function to fetch historical data\n",
    "def fetch_historical_data():\n",
    "    try:\n",
    "        nifty50_data = yf.Ticker(nifty50_ticker)\n",
    "        hist = nifty50_data.history(period=\"5d\")\n",
    "        hist.reset_index(inplace=True)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        hist = hist.drop(columns=[col for col in ['Dividends', 'Stock Splits', 'Volume'] if col in hist.columns])\n",
    "\n",
    "        hist['Date'] = hist['Date'].dt.strftime('%d-%b-%Y')  # Format date\n",
    "        return hist\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Function to standardize date formats in existing data\n",
    "def standardize_date_format(date_str):\n",
    "    for fmt in ('%d-%b-%Y', '%d-%b-%y', '%d-%m-%Y', '%Y-%m-%d'):\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    raise ValueError(f\"No valid date format found for {date_str}\")\n",
    "\n",
    "# Function to append data to the CSV file\n",
    "def append_data_to_csv(data, file):\n",
    "    try:\n",
    "        # Add placeholders for 'Shares Traded' and 'Turnover (₹ Cr)'\n",
    "        data['Shares Traded'] = None\n",
    "        data['Turnover (₹ Cr)'] = None\n",
    "        \n",
    "        # Ensure all required columns are present in the data\n",
    "        for column in required_columns:\n",
    "            if column not in data.columns:\n",
    "                data[column] = None\n",
    "\n",
    "        # Reorder columns to match the required columns\n",
    "        data = data[required_columns]\n",
    "\n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(file):\n",
    "            existing_df = pd.read_csv(file)\n",
    "            # Strip whitespace from column names\n",
    "            existing_df.columns = existing_df.columns.str.strip()\n",
    "            data.columns = data.columns.str.strip()\n",
    "\n",
    "            # Standardize date formats for comparison\n",
    "            existing_df['Date'] = existing_df['Date'].apply(standardize_date_format)\n",
    "            data['Date'] = data['Date'].apply(standardize_date_format)\n",
    "\n",
    "            # Combine existing data with new data, avoiding duplicates\n",
    "            updated_df = pd.concat([existing_df, data], ignore_index=True)\n",
    "            updated_df.drop_duplicates(subset='Date', keep='last', inplace=True)\n",
    "        else:\n",
    "            updated_df = data\n",
    "\n",
    "        # Save the updated DataFrame to the CSV file\n",
    "        updated_df.to_csv(file, index=False)\n",
    "        print(f\"Data appended to {file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error appending data to CSV: {e}\")\n",
    "\n",
    "# Run the data fetching and appending process\n",
    "def run_data_update():\n",
    "    if check_internet_connection():\n",
    "        historical_data = fetch_historical_data()\n",
    "        \n",
    "        if not historical_data.empty:\n",
    "            print(f\"Fetched historical data:\")\n",
    "            print(historical_data)\n",
    "            # Append the fetched historical data to CSV\n",
    "            append_data_to_csv(historical_data, csv_file)\n",
    "        else:\n",
    "            print(\"Failed to fetch historical data.\")\n",
    "    else:\n",
    "        print(\"No internet connection. Will retry in 10 minutes.\")\n",
    "        time.sleep(600)  # Wait for 10 minutes before retrying\n",
    "\n",
    "# Infinite loop to run the update every hour\n",
    "while True:\n",
    "    run_data_update()\n",
    "    time.sleep(3600)  # Sleep for 1 hour before running the update again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76479f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bfe427-ce30-4e6a-8faf-72c882e1d987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
